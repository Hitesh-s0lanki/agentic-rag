{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a474ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Prepare Vectorstore\n",
    "# -------------------------------\n",
    "docs = TextLoader(\"research_notes.txt\",encoding=\"utf-8\").load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(chunks, embedding)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "llm=init_chat_model(\"openai:gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. LangGraph State Definition\n",
    "# -------------------------------\n",
    "class RAGCoTState(BaseModel):\n",
    "    question: str\n",
    "    sub_steps: List[str] = []\n",
    "    retrieved_docs: List[Document] = []\n",
    "    answer: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Nodes\n",
    "# -------------------------------\n",
    "\n",
    "# a. Plan sub-questions\n",
    "def plan_steps(state:RAGCoTState)->RAGCoTState:\n",
    "    prompt=f\"Break the question into 2-3 reasoning steps: \\n\\n {state.question}\"\n",
    "    result=llm.invoke(prompt).content\n",
    "    subqs=[line.strip(\"- \") for line in result.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    return state.model_copy(update={\"sub_steps\":subqs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ddb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Retrieve for each step\n",
    "def retrieve_per_step(state:RAGCoTState)-> RAGCoTState:\n",
    "    all_docs=[]\n",
    "    for sub in state.sub_steps:\n",
    "        docs = retriever.invoke(sub)\n",
    "        all_docs.extend(docs)\n",
    "    return state.model_copy(update={\"retrieved_docs\": all_docs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36793883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Generate Final Answer\n",
    "def generate_answer(state: RAGCoTState) -> RAGCoTState:\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    prompt = f\"\"\"\n",
    "You are answering a complex question using reasoning and retrieved documents.\n",
    "\n",
    "Question: {state.question}\n",
    "\n",
    "Relevant Information:\n",
    "{context}\n",
    "\n",
    "Now synthesize a well-reasoned final answer.\n",
    "\"\"\"\n",
    "    result = llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"answer\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa499b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. LangGraph Graph\n",
    "# -------------------------------\n",
    "builder = StateGraph(RAGCoTState)\n",
    "builder.add_node(\"planner\", plan_steps)\n",
    "builder.add_node(\"retriever\", retrieve_per_step)\n",
    "builder.add_node(\"responder\", generate_answer)\n",
    "\n",
    "builder.set_entry_point(\"planner\")\n",
    "builder.add_edge(\"planner\", \"retriever\")\n",
    "builder.add_edge(\"retriever\", \"responder\")\n",
    "builder.add_edge(\"responder\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5. Run CoT RAG Agent\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"what are the additional eperiments in Transformer eveluation?\"\n",
    "    state = RAGCoTState(question=query)\n",
    "    final = graph.invoke(state)\n",
    "\n",
    "    print(\"\\nðŸªœ Reasoning Steps:\", final[\"sub_steps\"])\n",
    "    print(\"\\nâœ… Final Answer:\\n\", final[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
